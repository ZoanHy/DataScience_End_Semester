{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import string\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing.pool import ThreadPool\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "def extract_links(url):\n",
    "    soup = get_soup(url)\n",
    "    aitems = []\n",
    "    for h3 in soup.find_all(\"h3\"):\n",
    "        try:\n",
    "            a = h3.a[\"href\"]\n",
    "        except:\n",
    "            KeyError\n",
    "        aitems.append(a)\n",
    "    return aitems\n",
    "\n",
    "\n",
    "all_links1 = [\n",
    "    f\"https://xwatch.vn/dong-ho-nam-pc85-page{idx_page}.html\"\n",
    "    for idx_page in range(1, 206)\n",
    "]\n",
    "all_links2 = [\n",
    "    f\"https://xwatch.vn/dong-ho-nu-pc86-page{idx_page}.html\"\n",
    "    for idx_page in range(1, 107)\n",
    "]\n",
    "\n",
    "all_links = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=25) as executor:\n",
    "    futures = [executor.submit(extract_links, url) for url in all_links1 + all_links2]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "all_links = [link for sublist in results for link in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = list(set(all_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        response = session.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "soup = get_soup(all_links[0])\n",
    "details = {}\n",
    "nameAndtype = soup.find(\"div\", class_=\"product_name\")\n",
    "ds = nameAndtype.getText().lower().replace(\"chính hãng\",\"\").strip().split(\" \")\n",
    "type = ds[-1].strip().upper()\n",
    "price = (\n",
    "    soup.find_all(\"h3\", class_=\"price_current\")[0]\n",
    "    .text.replace(\"₫\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "\n",
    "content = soup.find(\"div\", class_=\"table-condensed compare_table\")\n",
    "rows = content.find_all(\"tr\")\n",
    "for row in rows:\n",
    "    text = row.getText().replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "    if len(text.split(\":\")) == 2:\n",
    "        key, value = text.split(\":\")\n",
    "        details[key.lower().strip()] = value.strip()\n",
    "a = {\"Giá tiền\": price, \"Mã sản phẩm\": type, **details}\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        response = session.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup\n",
    "def get_product_info(url):\n",
    "    soup = get_soup(url)\n",
    "    details = {}\n",
    "    nameAndtype = soup.find(\"div\", class_=\"product_name\")\n",
    "    ds = nameAndtype.getText().lower().replace(\"chính hãng\",\"\").strip().split(\" \")\n",
    "    type = ds[-1].strip().upper()\n",
    "    price = (\n",
    "        soup.find_all(\"h3\", class_=\"price_current\")[0]\n",
    "        .text.replace(\"₫\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    content = soup.find(\"div\", class_=\"table-condensed compare_table\")\n",
    "    rows = content.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        text = row.getText().replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "        if len(text.split(\":\")) == 2:\n",
    "            key, value = text.split(\":\")\n",
    "            details[key.strip()] = value.strip()\n",
    "    a = {\"Giá tiền\": price, \"Mã sản phẩm\": type, **details}\n",
    "    print(a)\n",
    "    return {\"Giá tiền\": price, \"Mã sản phẩm\": type, **details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_data_from_web(all_links):\n",
    "    data_frame_watchs = pd.DataFrame()\n",
    "    with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "        results = executor.map(get_product_info, all_links)\n",
    "        for result in results:\n",
    "            data_frame_watchs = data_frame_watchs.append(result, ignore_index=True)\n",
    "    return data_frame_watchs\n",
    "\n",
    "data_frame_watchs = crawl_data_from_web(all_links)\n",
    "\n",
    "data_frame_watchs.to_csv(\"../main/raw_data/x_watch.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
